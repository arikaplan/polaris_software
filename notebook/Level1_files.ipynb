{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\akkap\\appdata\\local\\continuum\\anaconda3\\envs\\py27\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['Text', 'Button', 'datetime', 'Widget']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\cofe-python-analysis-tools\\\\utils_meinhold')\n",
    "sys.path.append('../utils_meinhold')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\cofe-python-analysis-tools\\\\utils_zonca')\n",
    "sys.path.append('../utils_zonca')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\cofe-python-analysis-tools\\\\utils_zonca\\\\pointing')\n",
    "sys.path.append('../utils_zonca/pointing')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\greenpol')\n",
    "sys.path.append('../')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\greenpol\\\\telescope_control\\\\')\n",
    "sys.path.append('../telescope_control')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\greenpol\\\\telescope_control\\\\VtoT\\\\')\n",
    "sys.path.append('../VtoT')\n",
    "import realtime_gp as rt\n",
    "import numpy as np\n",
    "import datetime  \n",
    "import h5py\n",
    "import pandas as pd\n",
    "from pointingtools import compute_parallactic_angle, altaz2ha \n",
    "from planets import getlocation\n",
    "import warnings\n",
    "from astropy.coordinates import AltAz, Angle, EarthLocation, ICRS, SkyCoord, frame_transform_graph, get_sun\n",
    "from astropy import units as u\n",
    "from astropy.time import Time\n",
    "import ephem\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "from planets import getlocation, getpointing\n",
    "\n",
    "import Tkinter,tkFileDialog\n",
    "\n",
    "from Tkinter import *\n",
    "import ttk\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import cPickle\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "%pylab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointing_files(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/pointing_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_times(fld):\n",
    "    startfile = fld[0][:43]+fld[0][49:-2]+'dat'\n",
    "    endfile = fld[-1][:43]+fld[-1][49:-2]+'dat'\n",
    "    \n",
    "    #starttime = os.path.getctime(startfile)\n",
    "    starttime= os.stat(startfile).st_mtime + 7*3600\n",
    "    starttime = datetime.datetime.fromtimestamp(starttime)\n",
    "    \n",
    "    #endtime = os.path.getctime(endfile)\n",
    "    endtime= os.stat(endfile).st_mtime + 7*3600\n",
    "    endtime = datetime.datetime.fromtimestamp(endtime)\n",
    "    \n",
    "    return starttime, endtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileStruct(n_array, chan, starttime, endtime, cleaned=False):\n",
    "\n",
    "    fpath = \"C:/software_git_repos/polaris/polaris_data/level1\"\n",
    "    os.chdir(fpath)\n",
    "    yrmoday = starttime.strftime('%Y%m%d')\n",
    "    path = '-'.join((starttime.strftime('%H_%M_%S'), endtime.strftime('%H_%M_%S')))\n",
    "    path = '-'.join((chan, path))\n",
    "    if cleaned:\n",
    "        path = path+'_cleaned'\n",
    "    print 'start time: ', starttime\n",
    "    print 'end time: ', endtime\n",
    "    print 'elapsed time: ', (endtime - starttime).total_seconds(), 'sec'\n",
    "    if not os.path.exists(yrmoday):#this is the first file being created for that time\n",
    "        os.makedirs(yrmoday)\n",
    "        #set index to 0\n",
    "\n",
    "    path = '/'.join((yrmoday,path))\n",
    "    path = '.'.join((path,\"h5\"))\n",
    "    with h5py.File(str(path).replace(\"pkl\",\"h5\"), mode=\"w\") as f:\n",
    "        f.create_dataset(\"data\", data=n_array.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_fraction(number, res):\n",
    "    amount = int(number/res)*res\n",
    "    remainder = number - amount\n",
    "    return amount if remainder < res/2. else amount+res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_some_data(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/demod_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    dlist=[]\n",
    "    for f in filelist:\n",
    "        hf=h5py.File(f)\n",
    "        dlist.append(hf['demod_data'])\n",
    "    d=np.concatenate(dlist)\n",
    "    hf.close() \n",
    "\n",
    "    datadict=d\n",
    "        \n",
    "    return datadict, filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gpstime(starttime, gpstime, ltoffset=0, bits_to_ms=2**24, format='seconds', ttype = 'utc', singletime=False):\n",
    "\n",
    "    #function to convert gpstime to UTC time or local time\n",
    "\n",
    "    #universal time day\n",
    "    ltoffset = ltoffset*60*60\n",
    "    utcday = starttime + datetime.timedelta(0, ltoffset)\n",
    "\n",
    "    #days since last sunday\n",
    "    idx = (utcday.weekday() + 1) % 7\n",
    "\n",
    "    #date of previous sunday in universal coord\n",
    "    sunday = utcday - datetime.timedelta(idx) \n",
    "\n",
    "    syear = int(str(sunday)[:4])\n",
    "    smonth = int(str(sunday)[5:7])\n",
    "    sday = int(str(sunday)[8:10])\n",
    "    \n",
    "    sunday = datetime.datetime(syear, smonth, sday, 0, 0, 0)\n",
    "\n",
    "    #seconds since last sunday\n",
    "    sundaysec = (utcday - sunday).total_seconds()\n",
    "\n",
    "    #convert to seconds\n",
    "    bits_to_sec = bits_to_ms/1000\n",
    "    \n",
    "    #number of wraps so far\n",
    "    numwraps = int(sundaysec/bits_to_sec)\n",
    "    \n",
    "    #time of last wrap\n",
    "    gpsstarttime = sunday + datetime.timedelta(0, numwraps*bits_to_sec)\n",
    "    \n",
    "    #convert gps starttime to timestamp\n",
    "    #gpsstarttime = (gpsstarttime-datetime.datetime(1970,1,1)).total_seconds()\n",
    "    gpsstarttime = time.mktime(gpsstarttime.timetuple())\n",
    "    \n",
    "    if singletime == False:\n",
    "        #find all wrap points in current data set\n",
    "        gpsdiff = np.diff(gpstime)\n",
    "        iwrap = np.where(gpsdiff < -2**24/1000/2)[0]\n",
    "        #iwrap = np.where(abs(gpsdiff) > 2**24/1000/2)[0]\n",
    "\n",
    "        #unwrap gpstime\n",
    "        for w in iwrap:\n",
    "            gpstime[w+1:] = gpstime[w+1:] + gpstime[w]\n",
    "\n",
    "    if ttype == 'utc':\n",
    "        ltoffset = 0\n",
    "    #gpstime gives seconds since starting point\n",
    "    dtime = gpsstarttime + gpstime - ltoffset\n",
    "\n",
    "        \n",
    "    if format == 'datetime':\n",
    "        if singletime == False:\n",
    "            t = []\n",
    "            for i in range(len(dtime)):\n",
    "                t.append(datetime.datetime.fromtimestamp(dtime[i]))\n",
    "        else:\n",
    "            t = datetime.datetime.fromtimestamp(dtime)\n",
    "        \n",
    "        return t, dtime\n",
    "    \n",
    "    else:\n",
    "        return dtime\n",
    "\n",
    "    '''\n",
    "    dtime = []\n",
    "     \n",
    "    for i in range(len(gpstime)):\n",
    "    #for i in range(0,1):\n",
    "        \n",
    "        if i>0:\n",
    "            if abs(gpstime[i] - gpstime[i-1]) > 2**24/1000/2:\n",
    "                print 'it got here'\n",
    "                gpstime[i:] = gpstime[i:] + gpstime[i-1]\n",
    "                \n",
    "        #gpstime gives seconds since starting point\n",
    "        t = gpsstarttime + datetime.timedelta(0,gpstime[i]) - datetime.timedelta(0, ltoffset)\n",
    "\n",
    "        if format == 'seconds':\n",
    "            timestamp = (t-datetime.datetime(1970,1,1)).total_seconds()\n",
    "            dtime.append(timestamp)\n",
    "        else:\n",
    "            dtime.append(t)\n",
    "          \n",
    "    return dtime\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flagging(channel, samples_per_rev, hkflags, baseline=False):\n",
    "    '''\n",
    "    Read time stream and apply flagging\n",
    "    '''\n",
    "\n",
    "    tod_len = np.size(channel)\n",
    "    \n",
    "    flags = np.ones(tod_len, dtype=bool)\n",
    "\n",
    "    if baseline == False:\n",
    "        baseline = 4*np.std(channel)\n",
    "    else:\n",
    "        baseline = baseline   \n",
    "\n",
    "\n",
    "    for i in range(int(tod_len/samples_per_rev)):\n",
    "        i_low  = i*samples_per_rev \n",
    "        i_high = i*samples_per_rev + samples_per_rev-1\n",
    "\n",
    "        sigma  = np.std(channel[i_low:i_high+1])\n",
    "\n",
    "        threshold = baseline/sigma \n",
    "        #print baseline\n",
    "\n",
    "        median = np.median(channel[i_low:i_high+1])\n",
    "\n",
    "        mask1  = np.array(np.where(channel[i_low:i_high+1]>median+threshold*sigma)) + i_low\n",
    "        mask2  = np.array(np.where(channel[i_low:i_high+1]<median-threshold*sigma)) + i_low\n",
    "\n",
    "        flags[mask1] = False\n",
    "        flags[mask2] = False\n",
    "        \n",
    "    #mask3 = np.where(hkflags != 1011)[0]\n",
    "    #flags[mask3] = False\n",
    "        \n",
    "    return flags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanish_data(data1, hkflags, samples_per_rev, data2=[]):\n",
    "    \n",
    "    dsmoothed = savgol_filter(data1, 51, 3)\n",
    "    d1 = np.diff(dsmoothed)\n",
    "    \n",
    "    flags = flagging(data1, samples_per_rev, hkflags)\n",
    "    flags2 = flagging(d1, samples_per_rev, hkflags)\n",
    "    \n",
    "    if len(data2) != 0:\n",
    "        dcleaned = data2.copy()\n",
    "    else:\n",
    "        dcleaned = data1.copy()\n",
    "        \n",
    "    dcleaned[np.where(flags==False)] = np.nan\n",
    "    dcleaned[np.where(flags2==False)] = np.nan\n",
    "    dcleaned[np.where(hkflags != 1011)] = np.nan\n",
    "    \n",
    "    return dcleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suncut(cut, gpstime, az, el, data):\n",
    "    \n",
    "    t = gpstime\n",
    "    sph = 60.\n",
    "    sps = sph/3600.\n",
    "    sunpoints = np.arange(t[0], t[-1] + (1/sps), 1/sps)\n",
    "\n",
    "    dt = convert_gpstime(starttime, sunpoints, ltoffset, format = 'datetime', ttype = 'ltc')[0]\n",
    "\n",
    "    times = Time(dt, scale='utc')\n",
    "\n",
    "    sun = get_sun(times)\n",
    "    loc = getlocation('Greenland')\n",
    "    sun = sun.transform_to(AltAz(obstime=times,location=loc))\n",
    "\n",
    "    saz = sun.az.deg\n",
    "    sel = sun.alt.deg\n",
    "\n",
    "    saz = np.interp(t, sunpoints, saz)\n",
    "    sel = np.interp(t, sunpoints, sel)\n",
    "    \n",
    "    angdiff = np.degrees(np.arccos(np.sin(np.radians(az))*np.sin(np.radians(saz)) \n",
    "                    + np.cos(np.radians(az))*np.cos(np.radians(saz))*np.cos(np.radians(el) - np.radians(sel))))\n",
    "    \n",
    "    dd = data*1\n",
    "    icut = np.where(abs(angdiff) < cut)[0]\n",
    "    dd[icut] = np.nan\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothTriangle(data, degree):\n",
    "    triangle=np.concatenate((np.arange(degree + 1), np.arange(degree)[::-1])) # up then down\n",
    "    smoothed=[]\n",
    "\n",
    "    for i in range(degree, len(data) - degree * 2):\n",
    "        point=data[i:i + len(triangle)] * triangle\n",
    "        smoothed.append(np.sum(point)/np.sum(triangle))\n",
    "    # Handle boundaries\n",
    "    smoothed=[smoothed[0]]*int(degree + degree/2) + smoothed\n",
    "    while len(smoothed) < len(data):\n",
    "        smoothed.append(smoothed[-1])\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\akkap\\appdata\\local\\continuum\\anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:11: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "dd, fld = read_some_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../realtime_gp.py:86: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  h=h5py.File(f)\n"
     ]
    }
   ],
   "source": [
    "flp = get_pointing_files()\n",
    "pp = rt.get_h5_pointing(flp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = rt.combine_cofe_h5_pointing(dd,pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-08-06 13:21:43.051726\n",
      "2018-08-06 15:56:58.835558\n",
      "<type 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "starttime, endtime = get_file_times(fld)\n",
    "\n",
    "print starttime\n",
    "print endtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = 'H1HiAC'\n",
    "var = 'T'\n",
    "LOCATION = 'Greenland'\n",
    "spr = 256#*30*60\n",
    "\n",
    "#gain in kelvin per volt\n",
    "changain = {'ch0':-4.11, 'ch1':-2.85*30., 'ch4':-9.47, 'ch8':-11.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "az = combined['az']\n",
    "el = combined['el']\n",
    "\n",
    "gpstime = dd['rev']/1000\n",
    "ltoffset = 0\n",
    "dtime, utime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime', ttype = 'ltc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combined['sci_data'][rt.nametochan(chan)][var]*changain[rt.nametochan(chan)]\n",
    "Q = combined['sci_data'][rt.nametochan(chan)]['Q']*changain[rt.nametochan(chan)]\n",
    "hkflags = combined['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#offset between local time and utctime in hours\n",
    "ltoffset = 0\n",
    "\n",
    "#seconds since last sunday utc\n",
    "gpstime = dd['rev']/1000#(combined['gpstime'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-ef137fecb20f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mgpstime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'rev'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpstime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mijump\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1e4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdmin\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "gpstime = dd['rev']\n",
    "diff = np.diff(gpstime)\n",
    "ijump = np.where(diff > 1e4)[0][0]\n",
    "dmax = diff.max()\n",
    "dmin = diff.min()\n",
    "print gpstime[ijump:ijump+2]\n",
    "gpstime[ijump+1:] -= (dmax - dmin)\n",
    "print gpstime[ijump:ijump+2]\n",
    "print diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file start time:  2018-08-06 13:21:43.051726\n",
      "gps converted start time:  2018-08-06 13:21:49.551000\n",
      "amount off in seconds:  6.499274\n",
      "file end time:  2018-08-06 15:56:58.835558\n",
      "gps converted end time:  2018-08-06 15:57:33.463000\n",
      "amount off in seconds:  34.627442\n"
     ]
    }
   ],
   "source": [
    "gpstime = dd['rev']/1000#(combined['gpstime'])/1000\n",
    "dtime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime', ttype = 'ltc')[0]\n",
    "tdiffe = (dtime[-1] - endtime).total_seconds()\n",
    "tdiffs = (dtime[0] - starttime).total_seconds()\n",
    "print 'file start time: ', starttime\n",
    "print 'gps converted start time: ', dtime[0]\n",
    "print 'amount off in seconds: ', tdiffs\n",
    "print 'file end time: ', endtime\n",
    "print 'gps converted end time: ', dtime[-1]\n",
    "print 'amount off in seconds: ', tdiffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpstime = dd['rev']/1000#(combined['gpstime'])/1000\n",
    "dtime, utime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.iers import conf\n",
    "conf.auto_max_age = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16400003433\n",
      "73.6820001602\n"
     ]
    }
   ],
   "source": [
    "az = combined['az']\n",
    "el = combined['el'] \n",
    "\n",
    "location = getlocation(LOCATION)\n",
    "\n",
    "t1 = time.time()\n",
    "#create ra dec sky object\n",
    "azel = SkyCoord(az = az, alt = el, obstime = dtime, location = location, frame = 'altaz', unit='deg')\n",
    "t2 = time.time()\n",
    "print t2-t1\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    #convert from ra dec to az/el for pointing\n",
    "    radec = azel.icrs\n",
    "print time.time()-t2\n",
    "ra = radec.ra.rad\n",
    "dec = radec.dec.rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZ = np.radians(az)\n",
    "EL = np.radians(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The latitude property is deprecated and may be removed in a future version.\n",
      "        Use `lat` instead. [astropy.utils.decorators]\n"
     ]
    }
   ],
   "source": [
    "lat = location.latitude.rad\n",
    "ha = altaz2ha(EL, AZ, lat)\n",
    "psi = compute_parallactic_angle(ha, lat, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to figure out units on TIME in andreas test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = True\n",
    "cut = 0.\n",
    "\n",
    "Tdata = combined['sci_data'][rt.nametochan(chan)]['T']*changain[rt.nametochan(chan)]\n",
    "Qdata = combined['sci_data'][rt.nametochan(chan)]['Q']*changain[rt.nametochan(chan)]\n",
    "Udata = combined['sci_data'][rt.nametochan(chan)]['U']*changain[rt.nametochan(chan)]\n",
    "\n",
    "if clean == True:\n",
    "    \n",
    "    Tcleaned = cleanish_data(Tdata, hkflags, spr)\n",
    "    Tfinal = Tcleaned[np.logical_not(np.isnan(Tcleaned))]\n",
    "    \n",
    "    raclean = ra[np.logical_not(np.isnan(Tcleaned))]\n",
    "    decclean = dec[np.logical_not(np.isnan(Tcleaned))]\n",
    "    psiclean = psi[np.logical_not(np.isnan(Tcleaned))]\n",
    "    \n",
    "    \n",
    "    Qcleaned = cleanish_data(Tdata, hkflags, spr, Qdata)\n",
    "    Qfinal = Qcleaned[np.logical_not(np.isnan(Qcleaned))]\n",
    "    \n",
    "    \n",
    "    Ucleaned = cleanish_data(Tdata, hkflags, spr, Udata)\n",
    "    Ufinal = Ucleaned[np.logical_not(np.isnan(Ucleaned))]\n",
    "\n",
    "    h5data = pd.DataFrame({\"TEMP\" : Tfinal})\n",
    "    h5data[\"PHI\"] = raclean\n",
    "    h5data[\"THETA\"] = np.pi/2 - decclean\n",
    "    h5data[\"PSI\"] = psiclean\n",
    "    h5data[\"FLAG\"] = np.zeros(len(psiclean))\n",
    "    h5data[\"Q\"] = Qfinal\n",
    "    h5data[\"U\"] = Ufinal\n",
    "    \n",
    "else:\n",
    "    h5data = pd.DataFrame({\"TEMP\" : Tdata})\n",
    "    h5data[\"PHI\"] = ra\n",
    "    h5data[\"THETA\"] = np.pi/2 - dec\n",
    "    h5data[\"PSI\"] = psi\n",
    "    h5data[\"FLAG\"] = np.zeros(len(psi))\n",
    "    h5data[\"Q\"] = Qdata\n",
    "    h5data[\"U\"] = Udata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (combined['gpstime'] - combined['gpstime'][0])/1000./60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2235d348>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(t, Tdata, label='Uncleaned')\n",
    "plot(t, Tcleaned, label='Cleaned')\n",
    "plot(t, dcut, label='cleaned + sun $\\Delta \\Theta > %s^{\\degree}$ removed' % cut)\n",
    "ylabel('Temperature (K)')\n",
    "xlabel('Minutes since 13:20')\n",
    "title('Greenland 8/6/2018 el = $70^{\\degree}$, %s %s' % (chan, 'T'))\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 45.\n",
    "dcut = suncut(cut, gpstime, az, el, Tcleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "#plot(angdiff, label='el')\n",
    "plot(t, data, label='data')\n",
    "plot(t, dcut, label='sun $\\Delta \\Theta > 45^{\\degree}$ removed')\n",
    "xlabel('minutes since start')\n",
    "ylabel('Temperature (K)')\n",
    "title('%s %s, start time: ' % (chan, var) + str(starttime))\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  2019-10-30 09:26:34.617700\n",
      "end time:  2019-10-30 13:38:17.860556\n",
      "elapsed time:  15103.242856 sec\n"
     ]
    }
   ],
   "source": [
    "fileStruct(h5data, chan, starttime, endtime, cleaned=clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "az = combined['az']\n",
    "el = combined['el'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "dd = combined['sci_data'][rt.nametochan(chan)]['Q']*changain[rt.nametochan(chan)]\n",
    "chan = 'H1HiAC'\n",
    "var = 'Q'\n",
    "res = 1.0\n",
    "plotnow_azelsig(h5data[\"TEMP\"], np.degrees(h5data[\"PHI\"]), np.degrees(h5data[\"THETA\"]), rt.nametochan(chan), var, res, radec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = cleanish_data(Tdata, hkflags, 256*30, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 5.\n",
    "dd = suncut(cut, saz, sel, az, el, Qcleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 'C:/software_git_repos/polaris/polaris_data/level1/20191025/ch0-07_43_20-15_11_19.h5'\n",
    "f2 = 'C:/software_git_repos/polaris/polaris_data/level1/20191030/ch0-09_26_34-13_38_17.h5'\n",
    "hf1 = h5py.File(f1)\n",
    "hf2 = h5py.File(f2)\n",
    "\n",
    "a = np.concatenate([hf1['data']['TIME'], hf2['data']['TIME']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a location (invalid object ID)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-4bf8bae4acc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\h5py\\_hl\\group.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Not a location (invalid object ID)"
     ]
    }
   ],
   "source": [
    "figure()\n",
    "plot(hf1['data']['Q'])\n",
    "plot(hf2['data']['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME\n"
     ]
    }
   ],
   "source": [
    "print h5data.keys()[0]\n",
    "f1 = 'C:/software_git_repos/polaris/polaris_data/level1/20191025/ch0-07_43_20-15_11_19.h5'\n",
    "f2 = 'C:/software_git_repos/polaris/polaris_data/level1/20191030/ch0-09_26_34-13_38_17.h5'\n",
    "hf1 = h5py.File(f1)\n",
    "hf2 = h5py.File(f2)\n",
    "\n",
    "TIME = np.concatenate([hf1['data']['TIME'], hf2['data']['TIME']])\n",
    "PHI = np.concatenate([hf1['data']['PHI'], hf2['data']['PHI']])\n",
    "THETA = np.concatenate([hf1['data']['THETA'], hf2['data']['THETA']])\n",
    "PSI = np.concatenate([hf1['data']['PSI'], hf2['data']['PSI']])\n",
    "FLAG = np.concatenate([hf1['data']['FLAG'], hf2['data']['FLAG']])\n",
    "TEMP = np.concatenate([hf1['data']['TEMP']*4.4/3.1, hf2['data']['TEMP']])\n",
    "Q = np.concatenate([hf1['data']['Q']*4.4/3.1, hf2['data']['Q']])\n",
    "U = np.concatenate([hf1['data']['U']*4.4/3.1, hf2['data']['U']])\n",
    "\n",
    "\n",
    "h5data_2days=pd.DataFrame({\"TIME\" : TIME}) \n",
    "h5data_2days[\"PHI\"] = PHI\n",
    "h5data_2days[\"THETA\"] = THETA\n",
    "h5data_2days[\"PSI\"] = PSI\n",
    "h5data_2days[\"FLAG\"] = FLAG\n",
    "h5data_2days[\"TEMP\"] = TEMP\n",
    "h5data_2days[\"Q\"] = Q\n",
    "h5data_2days[\"U\"] = U\n",
    "\n",
    "hf1.close()\n",
    "hf2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Closed HDF5 file>\n"
     ]
    }
   ],
   "source": [
    "print hf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_some_data(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/demod_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    dlist=[]\n",
    "    for f in filelist:\n",
    "        hf=h5py.File(f)\n",
    "        dlist.append(hf['demod_data'])\n",
    "    d=np.concatenate(dlist)\n",
    "    hf.close() \n",
    "\n",
    "    datadict=d\n",
    "        \n",
    "    return datadict, filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13646630>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(AZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azelsig(data, az, el, chan, var, res, minmax=None, radec=False, supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    ##dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\t\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data az and el values\n",
    "    az1, el1 = az.copy(), el.copy()\n",
    "    data = data\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data = convert.convert(data, 'i')\n",
    "    if chan == 13:\n",
    "        data = convert.convert(data, 'e')\n",
    "    if chan == 14:\n",
    "        data = convert.convert(data, 'h')\n",
    "    if chan == 15:\n",
    "        data = convert.convert(data, 'l')\n",
    "\n",
    "    steps = len(data)\n",
    "\n",
    "    #set az/el resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up bins/grid\n",
    "    if radec:\n",
    "        x, y = np.arange(0., 360.+dx, dx), np.arange(-90., 90. + dy, dy)\n",
    "    else:\n",
    "        x, y = np.arange(0., 360.+dx, dx), np.arange(0., 90. + dy, dy)\n",
    "    AZ, EL = np.meshgrid(x, y)\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #set up matrix for signal \n",
    "    z1 = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z1, (len(y), len(x)))\n",
    "\n",
    "    #set up matrix for keeping track of data points in single bin for averaging\n",
    "    z2 = np.zeros(len(x)*len(y))\n",
    "    count = np.reshape(z2, (len(y), len(x)))\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        #round az/el points for comparison with grid\t    \n",
    "        el1[i] = rt.round_fraction(el1[i], dy)\n",
    "        az1[i] = rt.round_fraction(az1[i], dx)  \n",
    "\n",
    "        #find where data points belong in grid\n",
    "        iel = np.where(abs(y - el1[i]) < epsilon)[0][0]\n",
    "        iaz = np.where(abs(x - az1[i]) < epsilon)[0][0]\n",
    "        \n",
    "        #add 1 each time data point lands in same bin\n",
    "        count[iel][iaz] += 1\n",
    "\n",
    "        #add total number of data values in bin\n",
    "        sig[iel][iaz] = sig[iel][iaz] + data[i]  \n",
    "    \n",
    "\n",
    "    #mask 0 count values so they dont show up in color plot\n",
    "    count = ma.masked_where(count == 0.0, count)\n",
    "\n",
    "    #take average of all data points in single bin\n",
    "    sig = sig/count\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    figure()\n",
    "    plt.pcolormesh(AZ, EL, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data.min(),data.max())\n",
    "    if radec == False:\n",
    "        plt.axis([AZ.min(), AZ.max(), EL.min(), EL.max()])\n",
    "        plt.ylabel('elevation (deg)')\n",
    "        plt.xlabel('azimuth (deg)')\n",
    "    else:\n",
    "        plt.axis([0., 360., -90, 90.])\n",
    "        plt.xlabel('ra (deg)')\n",
    "        plt.ylabel('dec (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and elevation' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x4fd89748>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:78: RuntimeWarning: Mean of empty slice.\n"
     ]
    }
   ],
   "source": [
    "chan = 'H1HiAC'\n",
    "var = 'T'\n",
    "az = combined['az']\n",
    "data = combined['sci_data'][rt.nametochan(chan)][var]\n",
    "plotnow_azrevsig(data, az, rt.nametochan(chan), var, res=1.0, minmax = [data.min()/20., data.max()/20.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azrevsig(data, az, chan, var, res = 1.0, minmax=None,supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    #dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data and az values\n",
    "    az1 = az\n",
    "    data1 = data\n",
    "    steps = len(data1)\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data1 = convert.convert(data1, 'i')\n",
    "    if chan == 13:\n",
    "        data1 = convert.convert(data1, 'e')\n",
    "    if chan == 14:\n",
    "        data1 = convert.convert(data1, 'h')\n",
    "    if chan == 15:\n",
    "        data1 = convert.convert(data1, 'l')\n",
    "\n",
    "    #resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up empty lists to append each revolution to\n",
    "    data = []\n",
    "    az = []\n",
    "    iaz = [0]\n",
    "    rev = 0\n",
    "\n",
    "    #determine indices in azimuth/data array which correspond to a new revolution of the telescope\n",
    "    for i in range(steps):\n",
    "        #round values to resolution for comparison later\n",
    "        az1[i] = round_fraction(az1[i], dx)\n",
    "        if i > 0:\n",
    "            if abs(az1[i] - az1[i-1]) >= 180.:\n",
    "                iaz.append(i)\n",
    "                rev += 1\n",
    "\n",
    "    #append each revolution array to a list\t    \n",
    "    for j in range(rev):\n",
    "        az.append(az1[iaz[j]:iaz[j+1]])\n",
    "        data.append(data1[iaz[j]:iaz[j+1]])\n",
    "\n",
    "    #append the last revolution\n",
    "    data.append(data1[iaz[-1]:])\n",
    "    az.append(az1[iaz[-1]:])\n",
    "    rev += 1\n",
    "\n",
    "    data = np.asarray(data)\n",
    "    az = np.asarray(az)\n",
    "\n",
    "    #create grid for plotting\n",
    "    x, y = np.arange(0., 360.+dx, dx), np.arange(0., rev - 1 + dy, dy)\n",
    "    AZ, REV = np.meshgrid(x, y)\n",
    "\n",
    "    #set up empty array\n",
    "    z = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z, (len(y), len(x)))\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #fill signal array with data points\n",
    "    for r in range(rev):\n",
    "        for a in range(len(x)):\n",
    "            #find indices where combined azimuth data fits on x grid\n",
    "            idx = np.where(abs(az[r] - x[a]) < epsilon)[0]\n",
    "            #if idx length is 0 this will create a mask on that point, in idx len > 1, avg data points in the same bin\n",
    "            sig[r][a] = data[r][idx].mean()\n",
    "\n",
    "    #mask invalid values, i.e. where there are no data points\n",
    "    sig = ma.masked_invalid(sig)\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    plt.pcolormesh(AZ, REV, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data1.min(),data1.max())\n",
    "    plt.axis([0., 360., 0., rev - 1])\n",
    "    plt.ylabel('revolution #')\n",
    "    plt.xlabel('azimuth (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and revolution #' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azelsig2(data, az, el, chan, var, res, minmax=None, radec=False, supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    ##dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\t\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data az and el values\n",
    "    az1, el1 = az, el\n",
    "    data = data\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data = convert.convert(data, 'i')\n",
    "    if chan == 13:\n",
    "        data = convert.convert(data, 'e')\n",
    "    if chan == 14:\n",
    "        data = convert.convert(data, 'h')\n",
    "    if chan == 15:\n",
    "        data = convert.convert(data, 'l')\n",
    "\n",
    "    steps = len(data)\n",
    "\n",
    "    #set az/el resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up bins/grid\n",
    "    x, y = np.arange(0., 360.+dx, dx), np.arange(0., 90. + dy, dy)\n",
    "    AZ, EL = np.meshgrid(x, y)\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #set up matrix for signal \n",
    "    z1 = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z1, (len(y), len(x)))\n",
    "\n",
    "    #set up matrix for keeping track of data points in single bin for averaging\n",
    "    z2 = np.zeros(len(x)*len(y))\n",
    "    count = np.reshape(z2, (len(y), len(x)))\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        #round az/el points for comparison with grid\t    \n",
    "        el1[i] = rt.round_fraction(el1[i], dy)\n",
    "        az1[i] = rt.round_fraction(az1[i], dx)  \n",
    "\n",
    "        #find where data points belong in grid\n",
    "        iel = np.where(abs(y - el1[i]) < epsilon)[0][0]\n",
    "        iaz = np.where(abs(x - az1[i]) < epsilon)[0][0]\n",
    "\n",
    "        #add 1 each time data point lands in same bin\n",
    "        count[iel][iaz] += 1\n",
    "\n",
    "        #add total number of data values in bin\n",
    "        sig[iel][iaz] = sig[iel][iaz] + data[i]  \n",
    "\n",
    "    #mask 0 count values so they dont show up in color plot\n",
    "    count = ma.masked_where(count == 0.0, count)\n",
    "\n",
    "    #take average of all data points in single bin\n",
    "    sig = sig/count\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    plt.pcolormesh(AZ, EL, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data.min(),data.max())\n",
    "    if radec == False:\n",
    "        plt.axis([AZ.min(), AZ.max(), EL.min(), EL.max()])\n",
    "        plt.ylabel('elevation (deg)')\n",
    "        plt.xlabel('azimuth (deg)')\n",
    "    else:\n",
    "        plt.axis([0., 360., -90, 90.])\n",
    "        plt.xlabel('ra (deg)')\n",
    "        plt.ylabel('dec (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and elevation' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
