{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['Text', 'Button', 'datetime', 'Widget', 'var']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../utils_meinhold')\n",
    "sys.path.append('../utils_zonca')\n",
    "sys.path.append('../utils_zonca/pointing')\n",
    "sys.path.append('../')\n",
    "sys.path.append('../telescope_control')\n",
    "sys.path.append('../VtoT')\n",
    "import realtime_gp as rt\n",
    "import numpy as np\n",
    "import datetime \n",
    "import h5py\n",
    "import pandas as pd\n",
    "from pointingtools import compute_parallactic_angle, altaz2ha \n",
    "#from planets import getlocation\n",
    "import warnings\n",
    "from astropy.coordinates import AltAz, Angle, EarthLocation, ICRS, SkyCoord, frame_transform_graph\n",
    "from astropy import units as u\n",
    "#import ephem\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import Tkinter,tkFileDialog\n",
    "\n",
    "from Tkinter import *\n",
    "import ttk\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import cPickle\n",
    "\n",
    "%pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getlocation(LOCATION):\n",
    "\t#observation locations\n",
    "\tlocations = dict(\n",
    "\t\t\t\t\tBarcroft  = EarthLocation( lat=Angle(37.5838176, 'deg'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlon=Angle(-118.2373297, 'deg'), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\theight=3800 * u.m),\n",
    "\t\t\t\t\tGreenland = EarthLocation( lat=Angle(72.5796, 'deg'), \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlon=Angle(-38.4592, 'deg'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\theight=3200 * u.m),\n",
    "\t\t\t\t\tUCSB      = EarthLocation( lat=Angle(34.414, 'deg'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlon=Angle(-119.843, 'deg'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\theight=14 * u.m),\n",
    "\t\t\t\t\tSedgwick      = EarthLocation( lat=Angle(34.7, 'deg'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tlon=Angle(-120.02, 'deg'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\theight=300 * u.m),\n",
    ")\n",
    "\n",
    "\treturn locations[LOCATION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointing_files(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/pointing_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_some_data(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/demod_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    dlist=[]\n",
    "    for f in filelist:\n",
    "        hf=h5py.File(f)\n",
    "        dlist.append(hf['demod_data'])\n",
    "    d=np.concatenate(dlist)\n",
    "    hf.close() \n",
    "\n",
    "    datadict=d\n",
    "        \n",
    "    return datadict, filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_times(fld):\n",
    "    startfile = fld[0][:43]+fld[0][49:-2]+'dat'\n",
    "    endfile = fld[-1][:43]+fld[-1][49:-2]+'dat'\n",
    "    \n",
    "    #starttime = os.path.getctime(startfile)\n",
    "    starttime= os.stat(startfile).st_mtime\n",
    "    starttime = datetime.datetime.fromtimestamp(starttime)\n",
    "\n",
    "    #endtime = os.path.getctime(endfile)\n",
    "    endtime= os.stat(endfile).st_mtime\n",
    "    endtime = datetime.datetime.fromtimestamp(endtime)\n",
    "    \n",
    "    return starttime, endtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileStruct(n_array, chan, starttime, endtime):\n",
    "\n",
    "    fpath = \"D:/software_git_repos/greenpol/telescope_control/data_aquisition/level1\"\n",
    "    os.chdir(fpath)\n",
    "    yrmoday = starttime.strftime('%Y%m%d')\n",
    "    path = '-'.join((starttime.strftime('%H_%M_%S'), endtime.strftime('%H_%M_%S')))\n",
    "    path = '-'.join((chan, path))\n",
    "    print 'start time: ', starttime\n",
    "    print 'end time: ', endtime\n",
    "    print 'elapsed time: ', (endtime - starttime).total_seconds(), 'sec'\n",
    "    if not os.path.exists(yrmoday):#this is the first file being created for that time\n",
    "        os.makedirs(yrmoday)\n",
    "        #set index to 0\n",
    "\n",
    "    path = '/'.join((yrmoday,path))\n",
    "    path = '.'.join((path,\"h5\"))\n",
    "    with h5py.File(str(path).replace(\"pkl\",\"h5\"), mode=\"w\") as f:\n",
    "        f.create_dataset(\"data\", data=n_array.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_fraction(number, res):\n",
    "    amount = int(number/res)*res\n",
    "    remainder = number - amount\n",
    "    return amount if remainder < res/2. else amount+res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gpstime(starttime, gpstime, ltoffset=0, bits_to_ms=2**24, format='seconds', ttype = 'utc', singletime=False):\n",
    "\n",
    "    #function to convert gpstime to UTC time or local time\n",
    "\n",
    "    #universal time day\n",
    "    ltoffset = ltoffset*60*60\n",
    "    utcday = starttime + datetime.timedelta(0, ltoffset)\n",
    "\n",
    "    #days since last sunday\n",
    "    idx = (utcday.weekday() + 1) % 7\n",
    "\n",
    "    #date of previous sunday in universal coord\n",
    "    sunday = utcday - datetime.timedelta(idx) \n",
    "\n",
    "    syear = int(str(sunday)[:4])\n",
    "    smonth = int(str(sunday)[5:7])\n",
    "    sday = int(str(sunday)[8:10])\n",
    "    \n",
    "    sunday = datetime.datetime(syear, smonth, sday, 0, 0, 0)\n",
    "\n",
    "    #seconds since last sunday\n",
    "    sundaysec = (utcday - sunday).total_seconds()\n",
    "\n",
    "    #convert to seconds\n",
    "    bits_to_sec = bits_to_ms/1000\n",
    "    \n",
    "    #number of wraps so far\n",
    "    numwraps = int(sundaysec/bits_to_sec)\n",
    "    \n",
    "    #time of last wrap\n",
    "    gpsstarttime = sunday + datetime.timedelta(0, numwraps*bits_to_sec)\n",
    "    \n",
    "    #convert gps starttime to timestamp\n",
    "    #gpsstarttime = (gpsstarttime-datetime.datetime(1970,1,1)).total_seconds()\n",
    "    gpsstarttime = time.mktime(gpsstarttime.timetuple())\n",
    "    \n",
    "    if singletime == False:\n",
    "        #find all wrap points in current data set\n",
    "        gpsdiff = np.diff(gpstime)\n",
    "        iwrap = np.where(gpsdiff < -2**24/1000/2)[0]\n",
    "        #iwrap = np.where(abs(gpsdiff) > 2**24/1000/2)[0]\n",
    "\n",
    "        #unwrap gpstime\n",
    "        for w in iwrap:\n",
    "            gpstime[w+1:] = gpstime[w+1:] + gpstime[w]\n",
    "\n",
    "    if ttype == 'utc':\n",
    "        ltoffset = 0\n",
    "    #gpstime gives seconds since starting point\n",
    "    dtime = gpsstarttime + gpstime - ltoffset\n",
    "\n",
    "        \n",
    "    if format == 'datetime':\n",
    "        if singletime == False:\n",
    "            t = []\n",
    "            for i in range(len(dtime)):\n",
    "                t.append(datetime.datetime.fromtimestamp(dtime[i]))\n",
    "        else:\n",
    "            t = datetime.datetime.fromtimestamp(dtime)\n",
    "        \n",
    "        return t, dtime\n",
    "    \n",
    "    else:\n",
    "        return dtime\n",
    "\n",
    "    '''\n",
    "    dtime = []\n",
    "     \n",
    "    for i in range(len(gpstime)):\n",
    "    #for i in range(0,1):\n",
    "        \n",
    "        if i>0:\n",
    "            if abs(gpstime[i] - gpstime[i-1]) > 2**24/1000/2:\n",
    "                print 'it got here'\n",
    "                gpstime[i:] = gpstime[i:] + gpstime[i-1]\n",
    "                \n",
    "        #gpstime gives seconds since starting point\n",
    "        t = gpsstarttime + datetime.timedelta(0,gpstime[i]) - datetime.timedelta(0, ltoffset)\n",
    "\n",
    "        if format == 'seconds':\n",
    "            timestamp = (t-datetime.datetime(1970,1,1)).total_seconds()\n",
    "            dtime.append(timestamp)\n",
    "        else:\n",
    "            dtime.append(t)\n",
    "          \n",
    "    return dtime\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azelsig(data, az, el, chan, var, res, minmax=None, radec=False, supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    ##dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\t\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data az and el values\n",
    "    az1, el1 = az, el\n",
    "    data = data\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data = convert.convert(data, 'i')\n",
    "    if chan == 13:\n",
    "        data = convert.convert(data, 'e')\n",
    "    if chan == 14:\n",
    "        data = convert.convert(data, 'h')\n",
    "    if chan == 15:\n",
    "        data = convert.convert(data, 'l')\n",
    "\n",
    "    steps = len(data)\n",
    "\n",
    "    #set az/el resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up bins/grid\n",
    "    x, y = np.arange(0., 360.+dx, dx), np.arange(0., 90. + dy, dy)\n",
    "    AZ, EL = np.meshgrid(x, y)\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #set up matrix for signal \n",
    "    z1 = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z1, (len(y), len(x)))\n",
    "\n",
    "    #set up matrix for keeping track of data points in single bin for averaging\n",
    "    z2 = np.zeros(len(x)*len(y))\n",
    "    count = np.reshape(z2, (len(y), len(x)))\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        #round az/el points for comparison with grid\t    \n",
    "        el1[i] = rt.round_fraction(el1[i], dy)\n",
    "        az1[i] = rt.round_fraction(az1[i], dx)  \n",
    "\n",
    "        #find where data points belong in grid\n",
    "        iel = np.where(abs(y - el1[i]) < epsilon)[0][0]\n",
    "        iaz = np.where(abs(x - az1[i]) < epsilon)[0][0]\n",
    "\n",
    "        #add 1 each time data point lands in same bin\n",
    "        count[iel][iaz] += 1\n",
    "\n",
    "        #add total number of data values in bin\n",
    "        sig[iel][iaz] = sig[iel][iaz] + data[i]  \n",
    "\n",
    "    #mask 0 count values so they dont show up in color plot\n",
    "    count = ma.masked_where(count == 0.0, count)\n",
    "\n",
    "    #take average of all data points in single bin\n",
    "    sig = sig/count\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    plt.pcolormesh(AZ, EL, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data1.min(),data1.max())\n",
    "    if radec == False:\n",
    "        plt.axis([AZ.min(), AZ.max(), EL.min(), EL.max()])\n",
    "        plt.ylabel('elevation (deg)')\n",
    "        plt.xlabel('azimuth (deg)')\n",
    "    else:\n",
    "        plt.axis([0., 360., -90, 90.])\n",
    "        plt.xlabel('ra (deg)')\n",
    "        plt.ylabel('dec (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and elevation' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azrevsig(data, az, chan, var, res = 1.0, minmax=None,supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    #dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "    figure()\n",
    "    #synchronized data and az values\n",
    "    az1 = az\n",
    "    data1 = data\n",
    "    steps = len(data1)\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data1 = convert.convert(data1, 'i')\n",
    "    if chan == 13:\n",
    "        data1 = convert.convert(data1, 'e')\n",
    "    if chan == 14:\n",
    "        data1 = convert.convert(data1, 'h')\n",
    "    if chan == 15:\n",
    "        data1 = convert.convert(data1, 'l')\n",
    "\n",
    "    #resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up empty lists to append each revolution to\n",
    "    data = []\n",
    "    az = []\n",
    "    iaz = [0]\n",
    "    rev = 0\n",
    "\n",
    "    #determine indices in azimuth/data array which correspond to a new revolution of the telescope\n",
    "    for i in range(steps):\n",
    "        #round values to resolution for comparison later\n",
    "        az1[i] = round_fraction(az1[i], dx)\n",
    "        if i > 0:\n",
    "            if abs(az1[i] - az1[i-1]) >= 180.:\n",
    "                iaz.append(i)\n",
    "                rev += 1\n",
    "\n",
    "    #append each revolution array to a list\t    \n",
    "    for j in range(rev):\n",
    "        az.append(az1[iaz[j]:iaz[j+1]])\n",
    "        data.append(data1[iaz[j]:iaz[j+1]])\n",
    "\n",
    "    #append the last revolution\n",
    "    data.append(data1[iaz[-1]:])\n",
    "    az.append(az1[iaz[-1]:])\n",
    "    rev += 1\n",
    "\n",
    "    data = np.asarray(data)\n",
    "    az = np.asarray(az)\n",
    "\n",
    "    #create grid for plotting\n",
    "    x, y = np.arange(0., 360.+dx, dx), np.arange(0., rev - 1 + dy, dy)\n",
    "    AZ, REV = np.meshgrid(x, y)\n",
    "\n",
    "    #set up empty array\n",
    "    z = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z, (len(y), len(x)))\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #fill signal array with data points\n",
    "    for r in range(rev):\n",
    "        for a in range(len(x)):\n",
    "            #find indices where combined azimuth data fits on x grid\n",
    "            idx = np.where(abs(az[r] - x[a]) < epsilon)[0]\n",
    "            #if idx length is 0 this will create a mask on that point, in idx len > 1, avg data points in the same bin\n",
    "            sig[r][a] = data[r][idx].mean()\n",
    "\n",
    "    #mask invalid values, i.e. where there are no data points\n",
    "    sig = ma.masked_invalid(sig)\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    plt.pcolormesh(AZ, REV, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data1.min(),data1.max())\t\n",
    "    plt.axis([0., 360., 0., rev - 1])\n",
    "    plt.ylabel('revolution #')\n",
    "    plt.xlabel('azimuth (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and revolution #' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azelsig2(data, az, el, chan, var, res, minmax=None, radec=False, supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    ##dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\t\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data az and el values\n",
    "    az1, el1 = az, el\n",
    "    data = data\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data = convert.convert(data, 'i')\n",
    "    if chan == 13:\n",
    "        data = convert.convert(data, 'e')\n",
    "    if chan == 14:\n",
    "        data = convert.convert(data, 'h')\n",
    "    if chan == 15:\n",
    "        data = convert.convert(data, 'l')\n",
    "\n",
    "    steps = len(data)\n",
    "\n",
    "    #set az/el resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up bins/grid\n",
    "    x, y = np.arange(0., 360.+dx, dx), np.arange(0., 90. + dy, dy)\n",
    "    AZ, EL = np.meshgrid(x, y)\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #set up matrix for signal \n",
    "    z1 = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z1, (len(y), len(x)))\n",
    "\n",
    "    #set up matrix for keeping track of data points in single bin for averaging\n",
    "    z2 = np.zeros(len(x)*len(y))\n",
    "    count = np.reshape(z2, (len(y), len(x)))\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        #round az/el points for comparison with grid\t    \n",
    "        el1[i] = rt.round_fraction(el1[i], dy)\n",
    "        az1[i] = rt.round_fraction(az1[i], dx)  \n",
    "\n",
    "        #find where data points belong in grid\n",
    "        iel = np.where(abs(y - el1[i]) < epsilon)[0][0]\n",
    "        iaz = np.where(abs(x - az1[i]) < epsilon)[0][0]\n",
    "\n",
    "        #add 1 each time data point lands in same bin\n",
    "        count[iel][iaz] += 1\n",
    "\n",
    "        #add total number of data values in bin\n",
    "        sig[iel][iaz] = sig[iel][iaz] + data[i]  \n",
    "\n",
    "    #mask 0 count values so they dont show up in color plot\n",
    "    count = ma.masked_where(count == 0.0, count)\n",
    "\n",
    "    #take average of all data points in single bin\n",
    "    sig = sig/count\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    plt.pcolormesh(AZ, EL, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data1.min(),data1.max())\n",
    "    if radec == False:\n",
    "        plt.axis([AZ.min(), AZ.max(), EL.min(), EL.max()])\n",
    "        plt.ylabel('elevation (deg)')\n",
    "        plt.xlabel('azimuth (deg)')\n",
    "    else:\n",
    "        plt.axis([0., 360., -90, 90.])\n",
    "        plt.xlabel('ra (deg)')\n",
    "        plt.ylabel('dec (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and elevation' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd, fld = read_some_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flp = get_pointing_files()\n",
    "pp = rt.get_h5_pointing(flp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = rt.combine_cofe_h5_pointing(dd,pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-28 02:04:43.930366\n",
      "2020-10-28 10:43:09.408498\n"
     ]
    }
   ],
   "source": [
    "starttime, endtime = get_file_times(fld)\n",
    "\n",
    "print starttime\n",
    "print endtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = 'ch8'\n",
    "var = 'Q'\n",
    "LOCATION = 'Sedgwick'\n",
    "\n",
    "#gain in kelvin per volt\n",
    "changain = {'ch0':-3.58, 'ch4':-9.47, 'ch8':-1.24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#offset between local time and utctime in hours\n",
    "ltoffset = 0\n",
    "\n",
    "#seconds since last sunday utc\n",
    "gpstime = dd['rev']/1000#(combined['gpstime'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file start time:  2020-10-28 02:04:43.930366\n",
      "gps converted start time:  2020-10-27 23:51:42.781000\n",
      "amount off in seconds:  -7981.149366\n",
      "file end time:  2020-10-28 10:43:09.408498\n",
      "gps converted end time:  2020-10-28 13:10:14.918000\n",
      "amount off in seconds:  8825.509502\n"
     ]
    }
   ],
   "source": [
    "gpstime = dd['rev']/1000#(combined['gpstime'])/1000\n",
    "dtime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime', ttype = 'ltc')[0]\n",
    "tdiffe = (dtime[-1] - endtime).total_seconds()\n",
    "tdiffs = (dtime[0] - starttime).total_seconds()\n",
    "print 'file start time: ', starttime\n",
    "print 'gps converted start time: ', dtime[0]\n",
    "print 'amount off in seconds: ', tdiffs\n",
    "print 'file end time: ', endtime\n",
    "print 'gps converted end time: ', dtime[-1]\n",
    "print 'amount off in seconds: ', tdiffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpstime = dd['rev']/1000#(combined['gpstime'])/1000\n",
    "dtime, utime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.30399990082\n",
      "235.506999969\n"
     ]
    }
   ],
   "source": [
    "AZ = combined['az']\n",
    "EL = combined['el'] \n",
    "\n",
    "location = getlocation(LOCATION)\n",
    "\n",
    "t1 = time.time()\n",
    "#create ra dec sky object\n",
    "azel = SkyCoord(az = AZ, alt = EL, obstime = dtime, location = location, frame = 'altaz', unit='deg')\n",
    "t2 = time.time()\n",
    "print t2-t1\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    #convert from ra dec to az/el for pointing\n",
    "    radec = azel.icrs\n",
    "print time.time()-t2\n",
    "ra = radec.ra.rad\n",
    "dec = radec.dec.rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZ = np.radians(AZ)\n",
    "EL = np.radians(EL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The latitude property is deprecated and may be removed in a future version.\n",
      "        Use `lat` instead. [astropy.utils.decorators]\n"
     ]
    }
   ],
   "source": [
    "lat = location.latitude.rad\n",
    "ha = altaz2ha(EL, AZ, lat)\n",
    "psi = compute_parallactic_angle(ha, lat, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to figure out units on TIME in andreas test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5data=pd.DataFrame({\"THETA\" : np.pi/2 - THETA })\n",
    "h5data=pd.DataFrame({\"TIME\" : utime}) \n",
    "h5data[\"PHI\"] = ra\n",
    "h5data[\"THETA\"] = np.pi/2 - dec\n",
    "h5data[\"PSI\"] = psi\n",
    "h5data[\"FLAG\"] = np.zeros(len(dtime)) \n",
    "h5data[\"TEMP\"] = combined['sci_data'][chan]['T']*changain[chan]\n",
    "h5data[\"Q\"] = combined['sci_data'][chan]['Q']*changain[chan]\n",
    "h5data[\"U\"] = combined['sci_data'][chan]['U']*changain[chan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fileStruct(h5data, chan, starttime, endtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12109518, -0.12554884, -0.12273669, ..., -0.1108706 ,\n",
       "       -0.11761546, -0.11788368])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined['sci_data']['ch8']['Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ch8'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-80769fe52834>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Q'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sci_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchan\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;31m#*changain[chan]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mplotnow_azelsig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mra\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnametochan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m5.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mradec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\software_git_repos\\Polaris\\polaris_software\\realtime_gp.pyc\u001b[0m in \u001b[0;36mnametochan\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    378\u001b[0m         'Cooler':'ch14', 'Calibrator':'ch15'}\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m     \u001b[0mchan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mchan\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ch8'"
     ]
    }
   ],
   "source": [
    "chan = 'H3HiAC'\n",
    "chan = rt.nametochan(chan)\n",
    "var = 'Q'\n",
    "data = combined['sci_data'][chan][var]#*changain[chan]\n",
    "plotnow_azelsig(data, np.degrees(ra), np.degrees(dec), rt.nametochan(chan), var, res=1.0, minmax = [data.min()/5., data.max()/5.], radec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure()\n",
    "plot(az[len(data)/2:], data[len(data)/2:], label='2nd half')\n",
    "plot(az[:len(data)/2], data[:len(data)/2], label='1st half')\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = 'H1HiAC'\n",
    "var = 'Q'\n",
    "az =  combined['az']\n",
    "data = combined['sci_data'][rt.nametochan(chan)][var]\n",
    "plotnow_azrevsig(data[:len(data)/2], az[:len(data)/2], rt.nametochan(chan), var, res = 1.0, minmax = [data.min()/30., data.max()/20.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = 'H1HiAC'\n",
    "var = 'Q'\n",
    "az =  combined['az']\n",
    "data = combined['sci_data'][rt.nametochan(chan)][var]\n",
    "plotnow_azrevsig(data[len(data)/2:], az[len(data)/2:], rt.nametochan(chan), var, res = 1.0, minmax = [data.min()/30., data.max()/20.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
