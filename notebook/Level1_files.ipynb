{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:161: UserWarning: pylab import has clobbered these variables: ['Widget', 'Text', 'Button', 'datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\cofe-python-analysis-tools\\\\utils_meinhold')\n",
    "sys.path.append('../utils_meinhold')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\cofe-python-analysis-tools\\\\utils_zonca')\n",
    "sys.path.append('../utils_zonca')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\cofe-python-analysis-tools\\\\utils_zonca\\\\pointing')\n",
    "sys.path.append('../utils_zonca/pointing')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\greenpol')\n",
    "sys.path.append('../')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\greenpol\\\\telescope_control\\\\')\n",
    "sys.path.append('../telescope_control')\n",
    "#sys.path.append('D:\\\\software_git_repos\\\\greenpol\\\\telescope_control\\\\VtoT\\\\')\n",
    "sys.path.append('../VtoT')\n",
    "import realtime_gp as rt\n",
    "import numpy as np\n",
    "import datetime  \n",
    "import h5py\n",
    "import pandas as pd\n",
    "from pointingtools import compute_parallactic_angle, altaz2ha \n",
    "from planets import getlocation\n",
    "import warnings\n",
    "from astropy.coordinates import AltAz, Angle, EarthLocation, ICRS, SkyCoord, frame_transform_graph\n",
    "from astropy import units as u\n",
    "import ephem\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from datetime import datetime\n",
    "from planets import getlocation, getpointing\n",
    "\n",
    "import Tkinter,tkFileDialog\n",
    "\n",
    "from Tkinter import *\n",
    "import ttk\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import cPickle\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "%pylab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pointing_files(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/pointing_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    return filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_times(fld):\n",
    "    startfile = fld[0][:43]+fld[0][49:-2]+'dat'\n",
    "    endfile = fld[-1][:43]+fld[-1][49:-2]+'dat'\n",
    "    \n",
    "    #starttime = os.path.getctime(startfile)\n",
    "    starttime= os.stat(startfile).st_mtime + 7*3600\n",
    "    starttime = datetime.datetime.fromtimestamp(starttime)\n",
    "    \n",
    "    #endtime = os.path.getctime(endfile)\n",
    "    endtime= os.stat(endfile).st_mtime + 7*3600\n",
    "    endtime = datetime.datetime.fromtimestamp(endtime)\n",
    "    \n",
    "    return starttime, endtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileStruct(n_array, chan, starttime, endtime, cleaned=False):\n",
    "\n",
    "    fpath = \"C:/software_git_repos/polaris/polaris_data/level1\"\n",
    "    os.chdir(fpath)\n",
    "    yrmoday = starttime.strftime('%Y%m%d')\n",
    "    path = '-'.join((starttime.strftime('%H_%M_%S'), endtime.strftime('%H_%M_%S')))\n",
    "    path = '-'.join((yrmoday, path))\n",
    "    path = '-'.join((chan, path))\n",
    "    if cleaned:\n",
    "        path = path+'_cleaned'\n",
    "    print 'start time: ', starttime\n",
    "    print 'end time: ', endtime\n",
    "    print 'elapsed time: ', (endtime - starttime).total_seconds(), 'sec'\n",
    "    if not os.path.exists(yrmoday):#this is the first file being created for that time\n",
    "        os.makedirs(yrmoday)\n",
    "        #set index to 0\n",
    "\n",
    "    path = '/'.join((yrmoday,path))\n",
    "    path = '.'.join((path,\"h5\"))\n",
    "    with h5py.File(str(path).replace(\"pkl\",\"h5\"), mode=\"w\") as f:\n",
    "        f.create_dataset(\"data\", data=n_array.to_records(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_fraction(number, res):\n",
    "    amount = int(number/res)*res\n",
    "    remainder = number - amount\n",
    "    return amount if remainder < res/2. else amount+res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_some_data(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/demod_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    dlist=[]\n",
    "    for f in filelist:\n",
    "        hf=h5py.File(f)\n",
    "        dlist.append(hf['demod_data'])\n",
    "    d=np.concatenate(dlist)\n",
    "    hf.close() \n",
    "\n",
    "    datadict=d\n",
    "        \n",
    "    return datadict, filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_gpstime(starttime, gpstime, ltoffset=0, bits_to_ms=2**24, format='seconds', ttype = 'utc', singletime=False):\n",
    "\n",
    "    #function to convert gpstime to UTC time or local time\n",
    "\n",
    "    #universal time day\n",
    "    ltoffset = ltoffset*60*60\n",
    "    utcday = starttime + datetime.timedelta(0, ltoffset)\n",
    "\n",
    "    #days since last sunday\n",
    "    idx = (utcday.weekday() + 1) % 7\n",
    "\n",
    "    #date of previous sunday in universal coord\n",
    "    sunday = utcday - datetime.timedelta(idx) \n",
    "\n",
    "    syear = int(str(sunday)[:4])\n",
    "    smonth = int(str(sunday)[5:7])\n",
    "    sday = int(str(sunday)[8:10])\n",
    "    \n",
    "    sunday = datetime.datetime(syear, smonth, sday, 0, 0, 0)\n",
    "\n",
    "    #seconds since last sunday\n",
    "    sundaysec = (utcday - sunday).total_seconds()\n",
    "\n",
    "    #convert to seconds\n",
    "    bits_to_sec = bits_to_ms/1000\n",
    "    \n",
    "    #number of wraps so far\n",
    "    numwraps = int(sundaysec/bits_to_sec)\n",
    "    \n",
    "    #time of last wrap\n",
    "    gpsstarttime = sunday + datetime.timedelta(0, numwraps*bits_to_sec)\n",
    "    \n",
    "    #convert gps starttime to timestamp\n",
    "    #gpsstarttime = (gpsstarttime-datetime.datetime(1970,1,1)).total_seconds()\n",
    "    gpsstarttime = time.mktime(gpsstarttime.timetuple())\n",
    "    \n",
    "    if singletime == False:\n",
    "        #find all wrap points in current data set\n",
    "        gpsdiff = np.diff(gpstime)\n",
    "        iwrap = np.where(gpsdiff < -2**24/1000/2)[0]\n",
    "        #iwrap = np.where(abs(gpsdiff) > 2**24/1000/2)[0]\n",
    "\n",
    "        #unwrap gpstime\n",
    "        for w in iwrap:\n",
    "            gpstime[w+1:] = gpstime[w+1:] + gpstime[w]\n",
    "\n",
    "    if ttype == 'utc':\n",
    "        ltoffset = 0\n",
    "    #gpstime gives seconds since starting point\n",
    "    dtime = gpsstarttime + gpstime - ltoffset\n",
    "\n",
    "        \n",
    "    if format == 'datetime':\n",
    "        if singletime == False:\n",
    "            t = []\n",
    "            for i in range(len(dtime)):\n",
    "                t.append(datetime.datetime.fromtimestamp(dtime[i]))\n",
    "        else:\n",
    "            t = datetime.datetime.fromtimestamp(dtime)\n",
    "        \n",
    "        return t, dtime\n",
    "    \n",
    "    else:\n",
    "        return dtime\n",
    "\n",
    "    '''\n",
    "    dtime = []\n",
    "     \n",
    "    for i in range(len(gpstime)):\n",
    "    #for i in range(0,1):\n",
    "        \n",
    "        if i>0:\n",
    "            if abs(gpstime[i] - gpstime[i-1]) > 2**24/1000/2:\n",
    "                print 'it got here'\n",
    "                gpstime[i:] = gpstime[i:] + gpstime[i-1]\n",
    "                \n",
    "        #gpstime gives seconds since starting point\n",
    "        t = gpsstarttime + datetime.timedelta(0,gpstime[i]) - datetime.timedelta(0, ltoffset)\n",
    "\n",
    "        if format == 'seconds':\n",
    "            timestamp = (t-datetime.datetime(1970,1,1)).total_seconds()\n",
    "            dtime.append(timestamp)\n",
    "        else:\n",
    "            dtime.append(t)\n",
    "          \n",
    "    return dtime\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flagging(channel, samples_per_rev, hkflags, baseline=False):\n",
    "    '''\n",
    "    Read time stream and apply flagging\n",
    "    '''\n",
    "\n",
    "    tod_len = np.size(channel)\n",
    "    \n",
    "    flags = np.ones(tod_len, dtype=bool)\n",
    "\n",
    "    if baseline == False:\n",
    "        baseline = 4*np.std(channel)\n",
    "    else:\n",
    "        baseline = baseline   \n",
    "\n",
    "\n",
    "    for i in range(int(tod_len/samples_per_rev)):\n",
    "        i_low  = i*samples_per_rev \n",
    "        i_high = i*samples_per_rev + samples_per_rev-1\n",
    "\n",
    "        sigma  = np.std(channel[i_low:i_high+1])\n",
    "\n",
    "        threshold = baseline/sigma \n",
    "        #print baseline\n",
    "\n",
    "        median = np.median(channel[i_low:i_high+1])\n",
    "\n",
    "        mask1  = np.array(np.where(channel[i_low:i_high+1]>median+threshold*sigma)) + i_low\n",
    "        mask2  = np.array(np.where(channel[i_low:i_high+1]<median-threshold*sigma)) + i_low\n",
    "\n",
    "        flags[mask1] = False\n",
    "        flags[mask2] = False\n",
    "        \n",
    "    #mask3 = np.where(hkflags != 1011)[0]\n",
    "    #flags[mask3] = False\n",
    "        \n",
    "    return flags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanish_data(data1, hkflags, samples_per_rev, data2=[]):\n",
    "    \n",
    "    dsmoothed = savgol_filter(data1, 51, 3)\n",
    "    d1 = np.diff(dsmoothed)\n",
    "    \n",
    "    flags = flagging(data1, samples_per_rev, hkflags)\n",
    "    flags2 = flagging(d1, samples_per_rev, hkflags)\n",
    "    \n",
    "    if len(data2) != 0:\n",
    "        dcleaned = data2.copy()\n",
    "    else:\n",
    "        dcleaned = data1.copy()\n",
    "    dcleaned[np.where(flags==False)] = np.nan\n",
    "    dcleaned[np.where(flags2==False)] = np.nan\n",
    "    dcleaned[np.where(hkflags != 1011)] = np.nan\n",
    "    \n",
    "    return dcleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothTriangle(data, degree):\n",
    "    triangle=np.concatenate((np.arange(degree + 1), np.arange(degree)[::-1])) # up then down\n",
    "    smoothed=[]\n",
    "\n",
    "    for i in range(degree, len(data) - degree * 2):\n",
    "        point=data[i:i + len(triangle)] * triangle\n",
    "        smoothed.append(np.sum(point)/np.sum(triangle))\n",
    "    # Handle boundaries\n",
    "    smoothed=[smoothed[0]]*int(degree + degree/2) + smoothed\n",
    "    while len(smoothed) < len(data):\n",
    "        smoothed.append(smoothed[-1])\n",
    "    return smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddict={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd, fld = read_some_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "flp = get_pointing_files()\n",
    "pp = rt.get_h5_pointing(flp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = rt.combine_cofe_h5_pointing(dd,pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (combined['gpstime'] - combined['gpstime'][0])/1000./3600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:43:20.641829\n",
      "2019-10-25 15:11:19.873233\n"
     ]
    }
   ],
   "source": [
    "starttime, endtime = get_file_times(fld)\n",
    "\n",
    "print starttime\n",
    "print endtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan = 'H1HiAC'\n",
    "var = 'T'\n",
    "LOCATION = 'Sedgwick'\n",
    "spr = 256\n",
    "\n",
    "#gain in kelvin per volt\n",
    "changain = {'ch0':-4.89, 'ch1':-2.85*30., 'ch4':-9.47, 'ch8':-11.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "az = combined['az']\n",
    "el = combined['el']\n",
    "\n",
    "gpstime = dd['rev']/1000\n",
    "ltoffset = 0\n",
    "dtime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime', ttype = 'ltc')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The longitude property is deprecated and may be removed in a future version.\n",
      "        Use `lon` instead. [astropy.utils.decorators]\n",
      "WARNING: AstropyDeprecationWarning: The latitude property is deprecated and may be removed in a future version.\n",
      "        Use `lat` instead. [astropy.utils.decorators]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#t = (combined['gpstime'] - combined['gpstime'][0])/1000./3600.\n",
    "t = combined['gpstime']/1000\n",
    "sph = 60.\n",
    "sps = sph/3600.\n",
    "sunpoints = np.arange(t[0], t[-1] + (1/sps), 1/sps)\n",
    "\n",
    "dt = convert_gpstime(starttime, sunpoints, ltoffset, format = 'datetime', ttype = 'ltc')[1]\n",
    "\n",
    "saz = []\n",
    "sel = []\n",
    "for d in dt:\n",
    "    sa, se = getpointing('Greenland', 'Sun', d)\n",
    "    saz.append(sa)\n",
    "    sel.append(se)\n",
    "    \n",
    "saz = np.asarray(saz)\n",
    "sel = np.asarray(sel)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saz = np.interp(combined['gpstime'], sunpoints, saz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The longitude property is deprecated and may be removed in a future version.\n",
      "        Use `lon` instead. [astropy.utils.decorators]\n",
      "WARNING: AstropyDeprecationWarning: The latitude property is deprecated and may be removed in a future version.\n",
      "        Use `lat` instead. [astropy.utils.decorators]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231.597027778 17.60175\n"
     ]
    }
   ],
   "source": [
    "saz, sel = getpointing('Greenland', 'Sun', dtime[0])\n",
    "print saz, sel\n",
    "\n",
    "saz = []\n",
    "sel = []\n",
    "for d in dtime:\n",
    "    sa, se = getpointing('Greenland', 'Sun', d)\n",
    "    saz.append(sa)\n",
    "    sel.append(se)\n",
    "    \n",
    "saz = np.asarray(saz)\n",
    "sel = np.asarray(sel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suncut(cut, saz, sel, az, el, data):\n",
    "    angdiff = np.degrees(np.arccos(np.sin(np.radians(az))*np.sin(np.radians(saz)) \n",
    "                    + np.cos(np.radians(az))*np.cos(np.radians(saz))*np.cos(np.radians(el) - np.radians(sel))))\n",
    "    \n",
    "    dd = data*1\n",
    "    icut = np.where(abs(angdiff) > cut)[0]\n",
    "    dd[icut] = np.nan\n",
    "    \n",
    "    return dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = suncut(5., saz, sel, az, el, az)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x8dd41b88>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x83c2cd48>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(az, label='angular distance')\n",
    "plot(dd, label='cut angular distance')\n",
    "#plot(data+45, label='data')\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combined['sci_data'][rt.nametochan(chan)][var]*changain[rt.nametochan(chan)]\n",
    "Q = combined['sci_data'][rt.nametochan(chan)]['Q']*changain[rt.nametochan(chan)]\n",
    "hkflags = combined['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#offset between local time and utctime in hours\n",
    "ltoffset = 0\n",
    "\n",
    "#seconds since last sunday utc\n",
    "gpstime = dd['rev']/1000#(combined['gpstime'])/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x983699b0>]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(dd['rev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33554420. 50331654.]\n",
      "[33554420. 33552992.]\n",
      "[30. 28. 30. ... 30. 28. 30.]\n"
     ]
    }
   ],
   "source": [
    "gpstime = dd['rev']\n",
    "diff = np.diff(gpstime)\n",
    "ijump = np.where(diff > 1e4)[0][0]\n",
    "dmax = diff.max()\n",
    "dmin = diff.min()\n",
    "print gpstime[ijump:ijump+2]\n",
    "gpstime[ijump+1:] -= (dmax - dmin)\n",
    "print gpstime[ijump:ijump+2]\n",
    "print diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file start time:  2019-10-25 07:43:20.641829\n",
      "gps converted start time:  2019-10-25 07:46:19.739000\n",
      "amount off in seconds:  179.097171\n",
      "file end time:  2019-10-25 15:11:19.873233\n",
      "gps converted end time:  2019-10-25 15:14:45.982000\n",
      "amount off in seconds:  206.108767\n"
     ]
    }
   ],
   "source": [
    "gpstime = dd['rev']/1000#(combined['gpstime'])/1000\n",
    "dtime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime', ttype = 'ltc')[0]\n",
    "tdiffe = (dtime[-1] - endtime).total_seconds()\n",
    "tdiffs = (dtime[0] - starttime).total_seconds()\n",
    "print 'file start time: ', starttime\n",
    "print 'gps converted start time: ', dtime[0]\n",
    "print 'amount off in seconds: ', tdiffs\n",
    "print 'file end time: ', endtime\n",
    "print 'gps converted end time: ', dtime[-1]\n",
    "print 'amount off in seconds: ', tdiffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpstime = dd['rev']/1000#(combined['gpstime'])/1000\n",
    "dtime, utime = convert_gpstime(starttime, gpstime, ltoffset, format = 'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.iers import conf\n",
    "conf.auto_max_age = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.20399999619\n",
      "224.978000164\n"
     ]
    }
   ],
   "source": [
    "az = combined['az']\n",
    "el = combined['el'] \n",
    "\n",
    "location = getlocation(LOCATION)\n",
    "\n",
    "t1 = time.time()\n",
    "#create ra dec sky object\n",
    "azel = SkyCoord(az = az, alt = el, obstime = dtime, location = location, frame = 'altaz', unit='deg')\n",
    "t2 = time.time()\n",
    "print t2-t1\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    #convert from ra dec to az/el for pointing\n",
    "    radec = azel.icrs\n",
    "print time.time()-t2\n",
    "ra = radec.ra.rad\n",
    "dec = radec.dec.rad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZ = np.radians(az)\n",
    "EL = np.radians(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: AstropyDeprecationWarning: The latitude property is deprecated and may be removed in a future version.\n",
      "        Use `lat` instead. [astropy.utils.decorators]\n"
     ]
    }
   ],
   "source": [
    "lat = location.latitude.rad\n",
    "ha = altaz2ha(EL, AZ, lat)\n",
    "psi = compute_parallactic_angle(ha, lat, dec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to figure out units on TIME in andreas test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr = 256#*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncleaned data\n",
    "#cleaned data\n",
    "Tdata = combined['sci_data'][rt.nametochan(chan)]['T']*changain[rt.nametochan(chan)]\n",
    "h5data = pd.DataFrame({\"TEMP\" : Tdata})\n",
    "\n",
    "h5data[\"PHI\"] = ra\n",
    "\n",
    "h5data[\"THETA\"] = np.pi/2 - dec\n",
    "\n",
    "h5data[\"PSI\"] = psi\n",
    "\n",
    "h5data[\"FLAG\"] = np.zeros(len(psi))\n",
    "\n",
    "Qdata = combined['sci_data'][rt.nametochan(chan)]['Q']*changain[rt.nametochan(chan)]\n",
    "h5data[\"Q\"] = Qdata\n",
    "\n",
    "Udata = combined['sci_data'][rt.nametochan(chan)]['U']*changain[rt.nametochan(chan)]\n",
    "h5data[\"U\"] = Udata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned data\n",
    "Tdata = combined['sci_data'][rt.nametochan(chan)]['T']*changain[rt.nametochan(chan)]\n",
    "Tcleaned = cleanish_data(Tdata, hkflags, spr)\n",
    "Tfinal = Tcleaned[np.logical_not(np.isnan(Tcleaned))]\n",
    "h5data = pd.DataFrame({\"TEMP\" : Tfinal})\n",
    "\n",
    "raclean = ra[np.logical_not(np.isnan(Tcleaned))]\n",
    "h5data[\"PHI\"] = raclean\n",
    "\n",
    "decclean = dec[np.logical_not(np.isnan(Tcleaned))]\n",
    "h5data[\"THETA\"] = np.pi/2 - decclean\n",
    "\n",
    "psiclean = psi[np.logical_not(np.isnan(Tcleaned))]\n",
    "h5data[\"PSI\"] = psiclean\n",
    "\n",
    "h5data[\"FLAG\"] = np.zeros(len(psiclean))\n",
    "\n",
    "Qdata = combined['sci_data'][rt.nametochan(chan)]['Q']*changain[rt.nametochan(chan)]\n",
    "Qcleaned = cleanish_data(Tdata, hkflags, spr, Qdata)\n",
    "Qfinal = Qcleaned[np.logical_not(np.isnan(Qcleaned))]\n",
    "h5data[\"Q\"] = Qfinal\n",
    "\n",
    "Udata = combined['sci_data'][rt.nametochan(chan)]['U']*changain[rt.nametochan(chan)]\n",
    "Ucleaned = cleanish_data(Tdata, hkflags, spr, Udata)\n",
    "Ufinal = Ucleaned[np.logical_not(np.isnan(Ucleaned))]\n",
    "h5data[\"U\"] = Ufinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:46:19.739000\n"
     ]
    }
   ],
   "source": [
    "print dtime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x4f299048>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(Qdata, label='Uncleaned')\n",
    "plot(Qcleaned, label='Cleaned')\n",
    "#plot(dd, label='sun cut: $\\Delta \\Theta > %s^{\\degree}$' % cut)\n",
    "ylabel('Volts')\n",
    "xlabel('Samples')\n",
    "title('Sedgwick 10/25/19 el = $70^{\\degree}$, %s %s' % (chan, 'Q'))\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:  2019-10-25 07:43:20.641829\n",
      "end time:  2019-10-25 15:11:19.873233\n",
      "elapsed time:  26879.231404 sec\n"
     ]
    }
   ],
   "source": [
    "fileStruct(h5data, chan, starttime, endtime, cleaned=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "az = combined['az']\n",
    "el = combined['el'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:73: RuntimeWarning: invalid value encountered in divide\n"
     ]
    }
   ],
   "source": [
    "dd = combined['sci_data'][rt.nametochan(chan)]['Q']*changain[rt.nametochan(chan)]\n",
    "chan = 'H1HiAC'\n",
    "var = 'Q'\n",
    "res = 1.0\n",
    "plotnow_azelsig(h5data[\"TEMP\"], np.degrees(h5data[\"PHI\"]), np.degrees(h5data[\"THETA\"]), rt.nametochan(chan), var, res, radec=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = cleanish_data(Tdata, hkflags, 256*30, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = 5.\n",
    "dd = suncut(cut, saz, sel, az, el, Qcleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 'C:/software_git_repos/polaris/polaris_data/level1/20191025/ch0-07_43_20-15_11_19.h5'\n",
    "f2 = 'C:/software_git_repos/polaris/polaris_data/level1/20191030/ch0-09_26_34-13_38_17.h5'\n",
    "hf1 = h5py.File(f1)\n",
    "hf2 = h5py.File(f2)\n",
    "\n",
    "a = np.concatenate([hf1['data']['TIME'], hf2['data']['TIME']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Not a location (invalid object ID)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-4bf8bae4acc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\h5py\\_hl\\group.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    260\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0moid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0motype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Not a location (invalid object ID)"
     ]
    }
   ],
   "source": [
    "figure()\n",
    "plot(hf1['data']['Q'])\n",
    "plot(hf2['data']['Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME\n"
     ]
    }
   ],
   "source": [
    "print h5data.keys()[0]\n",
    "f1 = 'C:/software_git_repos/polaris/polaris_data/level1/20191025/ch0-07_43_20-15_11_19.h5'\n",
    "f2 = 'C:/software_git_repos/polaris/polaris_data/level1/20191030/ch0-09_26_34-13_38_17.h5'\n",
    "hf1 = h5py.File(f1)\n",
    "hf2 = h5py.File(f2)\n",
    "\n",
    "TIME = np.concatenate([hf1['data']['TIME'], hf2['data']['TIME']])\n",
    "PHI = np.concatenate([hf1['data']['PHI'], hf2['data']['PHI']])\n",
    "THETA = np.concatenate([hf1['data']['THETA'], hf2['data']['THETA']])\n",
    "PSI = np.concatenate([hf1['data']['PSI'], hf2['data']['PSI']])\n",
    "FLAG = np.concatenate([hf1['data']['FLAG'], hf2['data']['FLAG']])\n",
    "TEMP = np.concatenate([hf1['data']['TEMP']*4.4/3.1, hf2['data']['TEMP']])\n",
    "Q = np.concatenate([hf1['data']['Q']*4.4/3.1, hf2['data']['Q']])\n",
    "U = np.concatenate([hf1['data']['U']*4.4/3.1, hf2['data']['U']])\n",
    "\n",
    "\n",
    "h5data_2days=pd.DataFrame({\"TIME\" : TIME}) \n",
    "h5data_2days[\"PHI\"] = PHI\n",
    "h5data_2days[\"THETA\"] = THETA\n",
    "h5data_2days[\"PSI\"] = PSI\n",
    "h5data_2days[\"FLAG\"] = FLAG\n",
    "h5data_2days[\"TEMP\"] = TEMP\n",
    "h5data_2days[\"Q\"] = Q\n",
    "h5data_2days[\"U\"] = U\n",
    "\n",
    "hf1.close()\n",
    "hf2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Closed HDF5 file>\n"
     ]
    }
   ],
   "source": [
    "print hf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_some_data(filelist=None):\n",
    "\n",
    "    if filelist==None:\n",
    "        root=Tkinter.Tk()\n",
    "        filelist = list(tkFileDialog.askopenfilenames(\\\n",
    "        initialdir='D://software_git_repos/greenpol/telescope_control/data_aquisition/demod_data/',parent=root,title='Choose a set of files'))\n",
    "        root.destroy()\n",
    "    filelist.sort()\n",
    "    \n",
    "    dlist=[]\n",
    "    for f in filelist:\n",
    "        hf=h5py.File(f)\n",
    "        dlist.append(hf['demod_data'])\n",
    "    d=np.concatenate(dlist)\n",
    "    hf.close() \n",
    "\n",
    "    datadict=d\n",
    "        \n",
    "    return datadict, filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13646630>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(AZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azelsig(data, az, el, chan, var, res, minmax=None, radec=False, supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    ##dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\t\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data az and el values\n",
    "    az1, el1 = az.copy(), el.copy()\n",
    "    data = data\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data = convert.convert(data, 'i')\n",
    "    if chan == 13:\n",
    "        data = convert.convert(data, 'e')\n",
    "    if chan == 14:\n",
    "        data = convert.convert(data, 'h')\n",
    "    if chan == 15:\n",
    "        data = convert.convert(data, 'l')\n",
    "\n",
    "    steps = len(data)\n",
    "\n",
    "    #set az/el resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up bins/grid\n",
    "    if radec:\n",
    "        x, y = np.arange(0., 360.+dx, dx), np.arange(-90., 90. + dy, dy)\n",
    "    else:\n",
    "        x, y = np.arange(0., 360.+dx, dx), np.arange(0., 90. + dy, dy)\n",
    "    AZ, EL = np.meshgrid(x, y)\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #set up matrix for signal \n",
    "    z1 = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z1, (len(y), len(x)))\n",
    "\n",
    "    #set up matrix for keeping track of data points in single bin for averaging\n",
    "    z2 = np.zeros(len(x)*len(y))\n",
    "    count = np.reshape(z2, (len(y), len(x)))\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        #round az/el points for comparison with grid\t    \n",
    "        el1[i] = rt.round_fraction(el1[i], dy)\n",
    "        az1[i] = rt.round_fraction(az1[i], dx)  \n",
    "\n",
    "        #find where data points belong in grid\n",
    "        iel = np.where(abs(y - el1[i]) < epsilon)[0][0]\n",
    "        iaz = np.where(abs(x - az1[i]) < epsilon)[0][0]\n",
    "        \n",
    "        #add 1 each time data point lands in same bin\n",
    "        count[iel][iaz] += 1\n",
    "\n",
    "        #add total number of data values in bin\n",
    "        sig[iel][iaz] = sig[iel][iaz] + data[i]  \n",
    "    \n",
    "\n",
    "    #mask 0 count values so they dont show up in color plot\n",
    "    count = ma.masked_where(count == 0.0, count)\n",
    "\n",
    "    #take average of all data points in single bin\n",
    "    sig = sig/count\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    figure()\n",
    "    plt.pcolormesh(AZ, EL, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data.min(),data.max())\n",
    "    if radec == False:\n",
    "        plt.axis([AZ.min(), AZ.max(), EL.min(), EL.max()])\n",
    "        plt.ylabel('elevation (deg)')\n",
    "        plt.xlabel('azimuth (deg)')\n",
    "    else:\n",
    "        plt.axis([0., 360., -90, 90.])\n",
    "        plt.xlabel('ra (deg)')\n",
    "        plt.ylabel('dec (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and elevation' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x4fd89748>]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure()\n",
    "plot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\labuser\\anaconda3\\envs\\py27\\lib\\site-packages\\ipykernel_launcher.py:78: RuntimeWarning: Mean of empty slice.\n"
     ]
    }
   ],
   "source": [
    "chan = 'H1HiAC'\n",
    "var = 'T'\n",
    "az = combined['az']\n",
    "data = combined['sci_data'][rt.nametochan(chan)][var]\n",
    "plotnow_azrevsig(data, az, rt.nametochan(chan), var, res=1.0, minmax = [data.min()/20., data.max()/20.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azrevsig(data, az, chan, var, res = 1.0, minmax=None,supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    #dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data and az values\n",
    "    az1 = az\n",
    "    data1 = data\n",
    "    steps = len(data1)\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data1 = convert.convert(data1, 'i')\n",
    "    if chan == 13:\n",
    "        data1 = convert.convert(data1, 'e')\n",
    "    if chan == 14:\n",
    "        data1 = convert.convert(data1, 'h')\n",
    "    if chan == 15:\n",
    "        data1 = convert.convert(data1, 'l')\n",
    "\n",
    "    #resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up empty lists to append each revolution to\n",
    "    data = []\n",
    "    az = []\n",
    "    iaz = [0]\n",
    "    rev = 0\n",
    "\n",
    "    #determine indices in azimuth/data array which correspond to a new revolution of the telescope\n",
    "    for i in range(steps):\n",
    "        #round values to resolution for comparison later\n",
    "        az1[i] = round_fraction(az1[i], dx)\n",
    "        if i > 0:\n",
    "            if abs(az1[i] - az1[i-1]) >= 180.:\n",
    "                iaz.append(i)\n",
    "                rev += 1\n",
    "\n",
    "    #append each revolution array to a list\t    \n",
    "    for j in range(rev):\n",
    "        az.append(az1[iaz[j]:iaz[j+1]])\n",
    "        data.append(data1[iaz[j]:iaz[j+1]])\n",
    "\n",
    "    #append the last revolution\n",
    "    data.append(data1[iaz[-1]:])\n",
    "    az.append(az1[iaz[-1]:])\n",
    "    rev += 1\n",
    "\n",
    "    data = np.asarray(data)\n",
    "    az = np.asarray(az)\n",
    "\n",
    "    #create grid for plotting\n",
    "    x, y = np.arange(0., 360.+dx, dx), np.arange(0., rev - 1 + dy, dy)\n",
    "    AZ, REV = np.meshgrid(x, y)\n",
    "\n",
    "    #set up empty array\n",
    "    z = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z, (len(y), len(x)))\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #fill signal array with data points\n",
    "    for r in range(rev):\n",
    "        for a in range(len(x)):\n",
    "            #find indices where combined azimuth data fits on x grid\n",
    "            idx = np.where(abs(az[r] - x[a]) < epsilon)[0]\n",
    "            #if idx length is 0 this will create a mask on that point, in idx len > 1, avg data points in the same bin\n",
    "            sig[r][a] = data[r][idx].mean()\n",
    "\n",
    "    #mask invalid values, i.e. where there are no data points\n",
    "    sig = ma.masked_invalid(sig)\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    plt.pcolormesh(AZ, REV, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data1.min(),data1.max())\n",
    "    plt.axis([0., 360., 0., rev - 1])\n",
    "    plt.ylabel('revolution #')\n",
    "    plt.xlabel('azimuth (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and revolution #' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotnow_azelsig2(data, az, el, chan, var, res, minmax=None, radec=False, supply_index=False):\n",
    "    #flp=select_h5(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #fld_demod, fld =select_dat(fpath,yrmoday,st_hour,st_minute,ed_hour,ed_minute)\n",
    "    #i=0\n",
    "    #while len(flp)<3:\n",
    "    #\ti+=1\n",
    "    #\tflp=select_h5(fpath,yrmoday,st_hour,int(st_minute)-i,ed_hour,int(ed_minute)+i)\n",
    "\n",
    "    #pp=get_h5_pointing(flp)\n",
    "    ##dd=get_demodulated_data_from_list(fld,supply_index=supply_index)\n",
    "    #dd=get_all_demodulated_data(fld_demod, fld)\t\n",
    "    #combined=combine_cofe_h5_pointing(dd,pp)\n",
    "\n",
    "    #synchronized data az and el values\n",
    "    az1, el1 = az, el\n",
    "    data = data\n",
    "\n",
    "    #convert to temp for cryo sensors\n",
    "    if chan == 12:\n",
    "        data = convert.convert(data, 'i')\n",
    "    if chan == 13:\n",
    "        data = convert.convert(data, 'e')\n",
    "    if chan == 14:\n",
    "        data = convert.convert(data, 'h')\n",
    "    if chan == 15:\n",
    "        data = convert.convert(data, 'l')\n",
    "\n",
    "    steps = len(data)\n",
    "\n",
    "    #set az/el resolution\n",
    "    dx = res\n",
    "    dy = res\n",
    "\n",
    "    #set up bins/grid\n",
    "    x, y = np.arange(0., 360.+dx, dx), np.arange(0., 90. + dy, dy)\n",
    "    AZ, EL = np.meshgrid(x, y)\n",
    "\n",
    "    #small number for comparing floats\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    #set up matrix for signal \n",
    "    z1 = np.zeros(len(x)*len(y))\n",
    "    sig = np.reshape(z1, (len(y), len(x)))\n",
    "\n",
    "    #set up matrix for keeping track of data points in single bin for averaging\n",
    "    z2 = np.zeros(len(x)*len(y))\n",
    "    count = np.reshape(z2, (len(y), len(x)))\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        #round az/el points for comparison with grid\t    \n",
    "        el1[i] = rt.round_fraction(el1[i], dy)\n",
    "        az1[i] = rt.round_fraction(az1[i], dx)  \n",
    "\n",
    "        #find where data points belong in grid\n",
    "        iel = np.where(abs(y - el1[i]) < epsilon)[0][0]\n",
    "        iaz = np.where(abs(x - az1[i]) < epsilon)[0][0]\n",
    "\n",
    "        #add 1 each time data point lands in same bin\n",
    "        count[iel][iaz] += 1\n",
    "\n",
    "        #add total number of data values in bin\n",
    "        sig[iel][iaz] = sig[iel][iaz] + data[i]  \n",
    "\n",
    "    #mask 0 count values so they dont show up in color plot\n",
    "    count = ma.masked_where(count == 0.0, count)\n",
    "\n",
    "    #take average of all data points in single bin\n",
    "    sig = sig/count\n",
    "\n",
    "    #change units on plot label\n",
    "    if int(chan[2:]) < 12:\n",
    "        unit = 'V'\n",
    "    else:\n",
    "        unit = 'K' \n",
    "\n",
    "    name = rt.chantoname(chan)\n",
    "\n",
    "    plt.pcolormesh(AZ, EL, sig)\n",
    "    plt.colorbar(label = 'Signal, %s' % unit)\n",
    "    if minmax != None:\n",
    "        plt.clim(minmax[0],minmax[1])\n",
    "    else:  \n",
    "        plt.clim(data.min(),data.max())\n",
    "    if radec == False:\n",
    "        plt.axis([AZ.min(), AZ.max(), EL.min(), EL.max()])\n",
    "        plt.ylabel('elevation (deg)')\n",
    "        plt.xlabel('azimuth (deg)')\n",
    "    else:\n",
    "        plt.axis([0., 360., -90, 90.])\n",
    "        plt.xlabel('ra (deg)')\n",
    "        plt.ylabel('dec (deg)')\n",
    "    plt.title('%s %s data binned to azimuth and elevation' % (name, var))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
